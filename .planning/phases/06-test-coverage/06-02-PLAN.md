---
phase: 06-test-coverage
plan: 02
type: execute
wave: 1
depends_on: []
files_modified:
  - tests/search/__init__.py
  - tests/search/test_db.py
  - tests/search/test_query.py
  - tests/search/test_utils.py
  - tests/search/test_formatter.py
autonomous: true

must_haves:
  truths:
    - "pytest runs search tests without real database"
    - "Database pool raises ValueError when COCOINDEX_DATABASE_URL not set"
    - "Query search returns SearchResult objects with score, filename, byte offsets"
    - "Utils correctly convert byte offsets to line numbers"
    - "Formatter produces valid JSON and readable pretty output"
  artifacts:
    - path: "tests/search/test_db.py"
      provides: "Database connection tests"
      min_lines: 30
    - path: "tests/search/test_query.py"
      provides: "Search query tests"
      min_lines: 50
    - path: "tests/search/test_utils.py"
      provides: "Utility function tests"
      min_lines: 60
    - path: "tests/search/test_formatter.py"
      provides: "Output formatting tests"
      min_lines: 50
  key_links:
    - from: "tests/search/test_query.py"
      to: "tests/fixtures/db.py"
      via: "mock_db_pool fixture"
      pattern: "mock_db_pool"
    - from: "tests/search/test_query.py"
      to: "tests/fixtures/ollama.py"
      via: "mock_code_to_embedding fixture"
      pattern: "mock_code_to_embedding"
---

<objective>
Create comprehensive tests for the search module covering database operations, query execution, utility functions, and output formatting.

Purpose: Fulfill TEST-SRC-01 through TEST-SRC-04 requirements with isolated tests using Phase 5 mock infrastructure.
Output: Test files in tests/search/ that pass with `pytest tests/search/`
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/06-test-coverage/06-CONTEXT.md
@.planning/phases/06-test-coverage/06-RESEARCH.md
@.planning/phases/05-test-infrastructure/05-02-SUMMARY.md
@.planning/phases/05-test-infrastructure/05-03-SUMMARY.md

# Source files to test
@src/cocosearch/search/db.py
@src/cocosearch/search/query.py
@src/cocosearch/search/utils.py
@src/cocosearch/search/formatter.py

# Existing fixtures
@tests/conftest.py
@tests/fixtures/db.py
@tests/fixtures/ollama.py
@tests/fixtures/data.py
@tests/mocks/db.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create search test directory and db/utils tests</name>
  <files>
    tests/search/__init__.py
    tests/search/test_db.py
    tests/search/test_utils.py
  </files>
  <action>
Create tests/search/__init__.py as empty package marker.

Create tests/search/test_db.py testing:
- TestGetConnectionPool:
  - test_raises_without_env_var: Raises ValueError when COCOINDEX_DATABASE_URL not set
  - Use patch.dict(os.environ, {}, clear=True) and reset db._pool = None before test
- TestGetTableName:
  - test_generates_correct_name: "myproject" -> "codeindex_myproject__myproject_chunks"
  - test_handles_underscores: "my_project" -> "codeindex_my_project__my_project_chunks"
  - test_preserves_case: Table names preserve the case of input

Create tests/search/test_utils.py testing:
- TestByteToLine:
  - test_start_of_file: Byte 0 returns line 1
  - test_after_newline: Byte after first newline returns line 2
  - test_middle_of_line: Byte in middle of line returns that line number
  - test_file_not_found_returns_zero: Non-existent file returns 0
- TestReadChunkContent:
  - test_reads_correct_bytes: Returns content between start_byte and end_byte
  - test_handles_utf8: Correctly decodes UTF-8 content
  - test_file_not_found_returns_empty: Non-existent file returns ""
- TestGetContextLines:
  - test_returns_lines_before_and_after: Gets context around chunk
  - test_handles_file_start: No lines before when chunk is at file start
  - test_handles_file_end: No lines after when chunk is at file end

Use tmp_path fixture to create test files with known content.
  </action>
  <verify>pytest tests/search/test_db.py tests/search/test_utils.py -v --tb=short</verify>
  <done>Database and utility tests pass</done>
</task>

<task type="auto">
  <name>Task 2: Create query and formatter tests</name>
  <files>
    tests/search/test_query.py
    tests/search/test_formatter.py
  </files>
  <action>
Create tests/search/test_query.py testing:
- TestSearchResult:
  - test_dataclass_fields: SearchResult has filename, start_byte, end_byte, score
- TestSearch:
  - test_returns_search_results: Returns list of SearchResult objects
  - test_applies_limit: Respects limit parameter
  - test_applies_min_score: Filters results below min_score
  - test_applies_language_filter: Filters by file extension when language specified

Use mock_db_pool and mock_code_to_embedding fixtures together. Pattern:
```python
def test_search_returns_results(mock_code_to_embedding, mock_db_pool):
    pool, cursor = mock_db_pool(results=[
        ("/path/file.py", 0, 100, 0.85),
    ])
    with patch("cocosearch.search.db.get_connection_pool", return_value=pool):
        results = search(query="test", index_name="testindex")
    assert len(results) == 1
    assert isinstance(results[0], SearchResult)
```

Create tests/search/test_formatter.py testing:
- TestFormatJson:
  - test_returns_valid_json: Output is parseable JSON
  - test_includes_file_info: JSON contains file_path, start_line, end_line, score
  - test_includes_content: JSON contains code content
- TestFormatPretty:
  - test_outputs_to_console: Writes to Rich console without error
  - test_shows_filename: Output contains filename
  - test_shows_score: Output contains similarity score

Use make_search_result and sample_search_results fixtures from tests/fixtures/data.py.
For format_pretty tests, use Console(file=io.StringIO(), force_terminal=True) to capture output.
Mock read_chunk_content and byte_to_line when testing formatters.
  </action>
  <verify>pytest tests/search/test_query.py tests/search/test_formatter.py -v --tb=short</verify>
  <done>Query and formatter tests pass with mocked dependencies</done>
</task>

<task type="auto">
  <name>Task 3: Verify all search tests and check coverage</name>
  <files>
    (no new files - verification only)
  </files>
  <action>
Run all search module tests together:
```bash
pytest tests/search/ -v --tb=short
```

Verify tests don't require real services:
```bash
COCOINDEX_DATABASE_URL="" pytest tests/search/ -v
```

Expected: ~20-25 tests passing across 4 test files.

If any tests fail, fix the issues by:
1. Checking mock setup is correct
2. Ensuring patches target the right import locations
3. Verifying fixtures are available (from conftest.py pytest_plugins)

Ensure tests cover:
- Happy paths for all functions
- Error cases (file not found, env var missing)
- Edge cases (empty results, start/end of file)
  </action>
  <verify>pytest tests/search/ -v --tb=short && echo "All search tests passed"</verify>
  <done>All search module tests pass (TEST-SRC-01 through TEST-SRC-04 complete)</done>
</task>

</tasks>

<verification>
```bash
# Run all search tests
pytest tests/search/ -v --tb=short

# Verify no real database called
COCOINDEX_DATABASE_URL="" pytest tests/search/ -v
```
</verification>

<success_criteria>
- tests/search/ directory exists with 4 test files
- All tests pass with mocked dependencies
- Tests cover: db connection/table naming, search queries, byte/line utils, JSON/pretty formatting
- No real PostgreSQL connections made during tests
</success_criteria>

<output>
After completion, create `.planning/phases/06-test-coverage/06-02-SUMMARY.md`
</output>
