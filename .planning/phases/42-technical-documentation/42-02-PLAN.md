---
phase: 42-technical-documentation
plan: 02
type: execute
wave: 1
depends_on: []
files_modified:
  - docs/retrieval.md
autonomous: true

must_haves:
  truths:
    - "Indexing pipeline is documented end-to-end: file reading -> chunking -> embedding -> metadata -> storage"
    - "Search pipeline is documented end-to-end: query -> embedding -> vector search -> keyword search -> RRF -> filtering -> ranking"
    - "RRF formula is shown with actual k=60 parameter and example calculation"
    - "Query caching documents both levels: exact (SHA256) and semantic (cosine >= 0.95), TTL 24h, invalidation on reindex"
    - "Definition boost (2x multiplier) is explained with when/how it applies"
    - "Symbol filtering is documented with supported types and languages"
  artifacts:
    - path: "docs/retrieval.md"
      provides: "Complete retrieval logic documentation"
      min_lines: 250
  key_links:
    - from: "docs/retrieval.md"
      to: "src/cocosearch/search/hybrid.py"
      via: "file reference"
      pattern: "hybrid\\.py"
    - from: "docs/retrieval.md"
      to: "src/cocosearch/search/cache.py"
      via: "file reference"
      pattern: "cache\\.py"
    - from: "docs/retrieval.md"
      to: "src/cocosearch/indexer/flow.py"
      via: "file reference"
      pattern: "flow\\.py"
---

<objective>
Create the retrieval logic documentation covering the complete indexing and search pipelines.

Purpose: Give both contributors and power users a deep understanding of how CocoSearch indexes code and retrieves results, including actual formulas, parameters, and implementation details.
Output: `docs/retrieval.md` with full end-to-end pipeline coverage.
</objective>

<execution_context>
@/Users/fedorzhdanov/.claude/get-shit-done/workflows/execute-plan.md
@/Users/fedorzhdanov/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/42-technical-documentation/42-CONTEXT.md
@.planning/phases/42-technical-documentation/42-RESEARCH.md
@src/cocosearch/indexer/flow.py
@src/cocosearch/indexer/config.py
@src/cocosearch/indexer/embedder.py
@src/cocosearch/indexer/tsvector.py
@src/cocosearch/indexer/symbols.py
@src/cocosearch/indexer/file_filter.py
@src/cocosearch/indexer/schema_migration.py
@src/cocosearch/search/query.py
@src/cocosearch/search/query_analyzer.py
@src/cocosearch/search/hybrid.py
@src/cocosearch/search/cache.py
@src/cocosearch/search/filters.py
@src/cocosearch/search/db.py
@src/cocosearch/search/context_expander.py
@src/cocosearch/handlers/__init__.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create docs/retrieval.md — Indexing Pipeline</name>
  <files>docs/retrieval.md</files>
  <action>
Create `docs/retrieval.md` with the first half covering the **Indexing Pipeline**. Structure:

**Title:** "Retrieval Logic"
**Introduction:** 2-3 sentences. CocoSearch uses a hybrid retrieval approach combining vector similarity search with keyword matching. This document covers both the indexing pipeline (how code enters the database) and the search pipeline (how queries retrieve results).

**Section: Core Concepts** (brief primer per user decision — don't assume familiarity):
- **Embeddings:** Dense numerical representations of text. CocoSearch uses Ollama's nomic-embed-text model to convert code chunks into 768-dimensional vectors. Similar code produces similar vectors, enabling semantic search.
- **Vector Search:** Finding the most similar vectors using cosine similarity. Higher cosine similarity = more relevant result. PostgreSQL's pgvector extension handles this natively.
- **Full-Text Search:** PostgreSQL's built-in text search using tsvector/tsquery. Matches exact tokens after preprocessing. Uses 'simple' configuration (no stemming) since code identifiers shouldn't be stemmed.
- **Reciprocal Rank Fusion (RRF):** Algorithm for merging two ranked lists into one. Uses rank positions (not scores) making it distribution-agnostic. Formula: `score = sum(1/(k + rank))` where k=60.

**Section: Indexing Pipeline** — Full end-to-end with numbered stages:

1. **File Discovery and Filtering**
   - CocoIndex LocalFile source reads from codebase directory
   - Exclusion patterns: built-in defaults + .gitignore patterns + user config patterns
   - Include patterns from config (default: all supported file types)
   - File: `src/cocosearch/indexer/file_filter.py` — `build_exclude_patterns()`

2. **Language Detection**
   - Maps file extension to language identifier via `extract_language()`
   - Handles extensionless files (e.g., `Dockerfile`)
   - 31 supported languages: 28 standard (Python, JS, TS, Go, Rust, Java, C, C++, Ruby, PHP, etc.) + 3 DevOps (HCL/Terraform, Dockerfile, Bash)
   - File: `src/cocosearch/indexer/embedder.py` — `extract_language()`

3. **Code Chunking**
   - CocoIndex's `SplitRecursively` with Tree-sitter for language-aware boundaries
   - Custom language definitions for DevOps files (HCL, Dockerfile, Bash) via handler registry
   - Parameters: chunk_size=1000 bytes, chunk_overlap=300 bytes (configurable)
   - Tree-sitter ensures chunks break at semantic boundaries (function/class/block boundaries) rather than arbitrary positions
   - File: `src/cocosearch/indexer/flow.py` — `create_code_index_flow()`

4. **Embedding Generation**
   - Each chunk → Ollama nomic-embed-text → 768-dimensional float vector
   - Uses CocoIndex's shared transform (embedding function evaluated once, reused across chunks)
   - File: `src/cocosearch/indexer/embedder.py` — `code_to_embedding`

5. **Metadata Extraction**
   - **DevOps metadata:** block_type (e.g., "resource", "FROM", "function"), hierarchy (e.g., "resource.aws_s3_bucket.data"), language_id (e.g., "hcl", "dockerfile", "bash")
   - **Symbol metadata:** symbol_type (function/class/method/interface), symbol_name (e.g., "UserService.get_user"), symbol_signature (e.g., "def get_user(user_id: int)")
   - Symbol extraction uses Tree-sitter queries — supported for 10 languages: Python, JavaScript, TypeScript, Go, Rust, Java, C, C++, Ruby, PHP
   - External .scm query files allow user extension of symbol patterns
   - File: `src/cocosearch/handlers/` — DevOps metadata; `src/cocosearch/indexer/symbols.py` — symbol extraction

6. **Text Preprocessing for Keyword Search**
   - Raw chunk text stored as `content_text` column
   - Preprocessed text for tsvector: splits camelCase/PascalCase/snake_case identifiers into constituent tokens
   - Example: "getUserById" → "get user by id getuserbyid" (both split tokens and original)
   - PostgreSQL generates `content_tsv` tsvector column using 'simple' config (no stemming)
   - GIN index on `content_tsv` for fast keyword search
   - File: `src/cocosearch/indexer/tsvector.py` — `text_to_tsvector_sql()`

7. **Storage**
   - CocoIndex exports to PostgreSQL table: `codeindex_{name}__{name}_chunks`
   - Primary key: (filename, location) — location is a byte range
   - Vector index on embedding column (cosine similarity metric)
   - GIN index on content_tsv column
   - Schema migration adds symbol columns (symbol_type, symbol_name, symbol_signature) if not present
   - File: `src/cocosearch/indexer/flow.py` — export configuration; `src/cocosearch/indexer/schema_migration.py`

Include a brief note: On reindex, the query cache for this index is invalidated first to prevent stale results.

Now continue in the same file with the **Search Pipeline** section. (Task 2 covers this — but both are written to the same file, so this task creates the file with both sections.)

**Section: Search Pipeline** — Full end-to-end with numbered stages:

1. **Query Cache Lookup**
   - Check cache BEFORE embedding generation (saves Ollama call on hit)
   - Two-level cache:
     - **L1 Exact Match:** SHA256 hash of (query, index_name, limit, min_score, language_filter, use_hybrid, symbol_type, symbol_name). Identical parameters → cache hit.
     - **L2 Semantic Match:** Cosine similarity of query embedding against cached embeddings. Threshold: >= 0.95. Purpose: cache hits for paraphrased queries ("find auth logic" vs "authentication handler").
   - Cache TTL: 24 hours (86400 seconds)
   - Eviction: Time-based expiry (entries removed on next access after TTL)
   - Invalidation: All entries for an index removed on reindex (`invalidate_index_cache()`)
   - Storage: In-memory dict (session-scoped singleton)
   - File: `src/cocosearch/search/cache.py` — `QueryCache`

2. **Query Analysis**
   - Identifier pattern detection: Checks for camelCase, PascalCase, snake_case patterns in query
   - Determines hybrid search mode:
     - `use_hybrid=None` (default): Auto-detect. If identifier patterns found AND content_tsv column exists → hybrid search
     - `use_hybrid=True`: Force hybrid (falls back to vector-only if tsvector column missing)
     - `use_hybrid=False`: Vector-only search
   - File: `src/cocosearch/search/query_analyzer.py` — `has_identifier_pattern()`

3. **Language and Symbol Filter Validation**
   - Language filter: Resolves aliases (terraform→hcl, shell→bash, sh→bash), validates against known languages
   - Symbol filter: Validates symbol_type values (function, class, method, interface), requires v1.7+ index with symbol columns
   - These filters are applied as SQL WHERE clauses BEFORE fusion (not after)
   - File: `src/cocosearch/search/query.py` — `validate_language_filter()`; `src/cocosearch/search/filters.py` — `build_symbol_where_clause()`

4. **Vector Similarity Search**
   - Query text → Ollama embedding → cosine similarity against stored embeddings
   - SQL: `1 - (embedding <=> %s::vector) AS score` (pgvector cosine distance operator)
   - ORDER BY embedding distance, LIMIT applied
   - Returns: filename, byte range, score, metadata (block_type, hierarchy, language_id, symbol info)
   - File: `src/cocosearch/search/hybrid.py` — `execute_vector_search()`

5. **Keyword Search** (hybrid mode only)
   - Query normalized: identifiers split into tokens (same logic as indexing)
   - PostgreSQL plainto_tsquery with 'simple' config against content_tsv column
   - Ranked by ts_rank (relevance scoring)
   - Graceful fallback: If content_tsv column doesn't exist, keyword search returns empty (vector-only results used)
   - File: `src/cocosearch/search/hybrid.py` — `execute_keyword_search()`

6. **RRF Fusion** (hybrid mode only)
   - **Formula:**
     ```
     RRF_score = sum(1 / (k + rank)) for each result list where result appears
     where k = 60 (standard RRF constant)
     ```
   - Both vector and keyword searches request 2x the limit (capped at 100) for better fusion coverage
   - Results identified by unique key: `filename:start_byte:end_byte`
   - Match types: "semantic" (vector only), "keyword" (keyword only), "both" (appeared in both lists)
   - Results appearing in both lists naturally score higher (two rank contributions vs one)
   - Tiebreaker: keyword matches preferred over semantic-only matches
   - **Example calculation:**
     ```
     Result at rank 3 in vector, rank 1 in keyword:
     RRF_score = 1/(60+3) + 1/(60+1) = 0.0159 + 0.0164 = 0.0323

     Result at rank 1 in vector only:
     RRF_score = 1/(60+1) = 0.0164
     ```
   - File: `src/cocosearch/search/hybrid.py` — `rrf_fusion()`

7. **Definition Boost**
   - Applied AFTER RRF fusion (preserves rank-based algorithm semantics)
   - Heuristic: Checks if chunk content starts with definition keywords (def, class, function, func, fn, struct, trait, etc.)
   - Boost: 2x score multiplier for definition chunks
   - Re-sorts results after boost
   - Requires v1.7+ index with symbol columns
   - File: `src/cocosearch/search/hybrid.py` — `apply_definition_boost()`

8. **Score Filtering and Result Assembly**
   - min_score threshold applied (default 0.0 — no filtering)
   - Results limited to requested count
   - HybridSearchResult → SearchResult conversion (uniform interface regardless of search mode)
   - Results cached for future queries (vector search includes embedding for L2 semantic cache)
   - File: `src/cocosearch/search/query.py` — `search()`

9. **Context Expansion** (MCP/output layer)
   - Default: Smart context expansion to enclosing function/class boundaries using Tree-sitter
   - Override: Explicit context_before/context_after line counts
   - 50-line context cap prevents unbounded growth
   - Instance-level LRU cache for file I/O during expansion (cleared after each search)
   - Supported languages for smart expansion: Python, JavaScript, TypeScript, Go, Rust
   - File: `src/cocosearch/search/context_expander.py` — `ContextExpander`

**Style guidelines:**
- Use "What It Does → How It Works → Implementation" pattern per research recommendations
- Include file path references for every stage
- Show actual parameter values (k=60, TTL=24h, chunk_size=1000, etc.)
- RRF formula shown as code block with example calculation
- Consistent terminology: "chunks" (not blocks/segments), "embeddings" (for the representation), "vector search" (for the operation)
- No diagrams (text descriptions only)
- Brief concept primer at top, then implementation details — serves both audiences
  </action>
  <verify>
- File `docs/retrieval.md` exists with 250+ lines
- Contains RRF formula with k=60
- Contains cache TTL "24 hours" or "86400"
- Contains semantic threshold "0.95"
- Contains chunk size "1000" and overlap "300"
- Contains definition boost "2x" or "2.0"
- Contains file path references (grep for "src/cocosearch")
- Contains both "Indexing Pipeline" and "Search Pipeline" sections
- `wc -l docs/retrieval.md` shows 250+ lines
  </verify>
  <done>Retrieval logic documentation covers the complete indexing and search pipelines end-to-end with actual formulas, parameters, and implementation file references</done>
</task>

</tasks>

<verification>
1. `docs/retrieval.md` exists with 250+ lines
2. Indexing pipeline covers all 7 stages (file discovery through storage)
3. Search pipeline covers all 9 stages (cache lookup through context expansion)
4. RRF formula shown with k=60 and example calculation
5. Cache documentation includes: two levels (exact + semantic), TTL (24h), threshold (0.95), invalidation
6. Definition boost documented (2x, applied after RRF)
7. All stages reference implementation files
</verification>

<success_criteria>
- A contributor can understand the complete data flow from indexing to search by reading this document
- A power user can understand why certain results rank higher than others
- All scoring formulas and parameters are documented with actual values from the codebase
- Query caching behavior is fully explained including cache key composition and eviction
</success_criteria>

<output>
After completion, create `.planning/phases/42-technical-documentation/42-02-SUMMARY.md`
</output>
