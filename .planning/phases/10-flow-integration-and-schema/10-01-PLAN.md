---
phase: 10-flow-integration-and-schema
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - src/cocosearch/indexer/flow.py
  - tests/indexer/test_flow.py
autonomous: true

must_haves:
  truths:
    - "DevOps file chunks carry block_type, hierarchy, and language_id metadata in PostgreSQL"
    - "Non-DevOps file chunks get empty-string metadata (not NULLs, not missing columns)"
    - "Primary keys remain [filename, location] -- schema migration is non-destructive"
    - "Pure Python codebases index identically to v1.1 plus three empty-string metadata columns"
  artifacts:
    - path: "src/cocosearch/indexer/flow.py"
      provides: "Wired metadata extraction in indexing pipeline"
      contains: "extract_devops_metadata"
    - path: "tests/indexer/test_flow.py"
      provides: "Tests verifying metadata fields in flow"
      contains: "metadata"
  key_links:
    - from: "src/cocosearch/indexer/flow.py"
      to: "src/cocosearch/indexer/metadata.py"
      via: "import and transform call"
      pattern: "from cocosearch\\.indexer\\.metadata import extract_devops_metadata"
    - from: "src/cocosearch/indexer/flow.py"
      to: "code_embeddings.collect()"
      via: "three new metadata kwargs"
      pattern: "block_type=chunk\\[\"metadata\"\\]\\[\"block_type\"\\]"
    - from: "src/cocosearch/indexer/flow.py"
      to: "code_embeddings.export()"
      via: "unchanged primary keys"
      pattern: "primary_key_fields=\\[\"filename\", \"location\"\\]"
---

<objective>
Wire metadata extraction into the CocoIndex indexing pipeline and extend the PostgreSQL schema with three new columns (block_type, hierarchy, language_id).

Purpose: After this plan, running `cocosearch index` on DevOps files produces chunks with populated metadata stored in PostgreSQL, completing the flow integration needed before Phase 4 (search/output) can surface metadata in results.

Output: Modified `flow.py` with metadata extraction transform and updated collect call; updated tests verifying the wiring.

NOTE: REQ-14 (pass `custom_languages` to `SplitRecursively`) was ALREADY completed in Phase 1 (plan 08-02). Line 67 of flow.py already contains `custom_languages=DEVOPS_CUSTOM_LANGUAGES`. This plan covers REQ-15, REQ-16, and REQ-17 only.
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/10-flow-integration-and-schema/10-CONTEXT.md
@.planning/phases/10-flow-integration-and-schema/10-RESEARCH.md

# Source files to modify
@src/cocosearch/indexer/flow.py
@tests/indexer/test_flow.py

# Reference: the metadata function being wired in
@src/cocosearch/indexer/metadata.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Wire metadata extraction into flow.py</name>
  <files>src/cocosearch/indexer/flow.py</files>
  <action>
Make exactly 3 localized changes to `src/cocosearch/indexer/flow.py`:

**Change 1 -- Add import (after existing imports, line 15 area):**
```python
from cocosearch.indexer.metadata import extract_devops_metadata
```

**Change 2 -- Add metadata transform (inside `with file["chunks"].row() as chunk:` block, AFTER the embedding call on line 77, BEFORE the collect call on line 80):**
```python
                # Extract DevOps metadata (block_type, hierarchy, language_id)
                chunk["metadata"] = chunk["text"].transform(
                    extract_devops_metadata,
                    language=file["extension"],
                )
```

Key details:
- `language=file["extension"]` -- pass the DataSlice, NOT a Python string. This matches the kwarg name `language` in `extract_devops_metadata(text: str, language: str)`.
- `file["extension"]` is the DataSlice produced by `extract_language` on line 62. It is accessible in the inner chunk loop (same cross-scope pattern already used by `SplitRecursively` on line 69).
- The transform runs for ALL chunks unconditionally. Non-DevOps files get empty strings from the function. Do NOT add conditional branching -- CocoIndex flows are declarative graph builders.

**Change 3 -- Extend collect call (add 3 new kwargs to existing `code_embeddings.collect()`):**
```python
                code_embeddings.collect(
                    filename=file["filename"],
                    location=chunk["location"],
                    embedding=chunk["embedding"],
                    block_type=chunk["metadata"]["block_type"],
                    hierarchy=chunk["metadata"]["hierarchy"],
                    language_id=chunk["metadata"]["language_id"],
                )
```

Key details:
- Use bracket notation to access struct sub-fields: `chunk["metadata"]["block_type"]`, NOT `chunk["metadata"]` as a whole struct.
- These three new fields become TEXT columns in PostgreSQL via CocoIndex schema inference.
- `primary_key_fields=["filename", "location"]` in the export call (line 90) MUST remain unchanged. Do NOT modify the export call.

**Do NOT change:**
- The `SplitRecursively` call (already has `custom_languages=DEVOPS_CUSTOM_LANGUAGES` from Phase 1)
- The export call (`primary_key_fields`, `vector_indexes`)
- The `run_index` function
- Any other existing code
  </action>
  <verify>
1. `python -c "from cocosearch.indexer.flow import create_code_index_flow, extract_devops_metadata; print('imports OK')"` succeeds
2. Visually confirm flow.py has exactly 3 changes: one new import, one transform call, three new collect kwargs
3. `grep -c "extract_devops_metadata" src/cocosearch/indexer/flow.py` returns 2 (one import, one usage)
4. `grep "primary_key_fields" src/cocosearch/indexer/flow.py` still shows `["filename", "location"]`
  </verify>
  <done>
- flow.py imports `extract_devops_metadata` from metadata module
- `chunk["metadata"]` transform call exists inside the chunk loop, after embedding, before collect
- `code_embeddings.collect()` includes `block_type`, `hierarchy`, `language_id` kwargs using bracket notation on `chunk["metadata"]`
- Primary keys unchanged: `["filename", "location"]`
- No other code modified
  </done>
</task>

<task type="auto">
  <name>Task 2: Add flow tests for metadata wiring</name>
  <files>tests/indexer/test_flow.py</files>
  <action>
Add a new test class `TestMetadataIntegration` to `tests/indexer/test_flow.py` that verifies the metadata extraction is properly wired into the flow. Follow the existing test patterns in the file (import inside test methods, use `unittest.mock`).

Tests to add:

**Test 1: `test_extract_devops_metadata_importable_from_flow`**
- Import `cocosearch.indexer.flow` as a module
- Assert `hasattr(flow_module, 'extract_devops_metadata')`
- Follows the pattern of `test_flow_module_imports_custom_languages` in `TestCustomLanguageIntegration`

**Test 2: `test_extract_devops_metadata_is_cocoindex_op`**
- Import `extract_devops_metadata` from `cocosearch.indexer.metadata`
- Assert it is callable
- Assert it has `__wrapped__` attribute or the cocoindex op function attributes (indicating it was decorated with `@cocoindex.op.function()`)

**Test 3: `test_flow_source_has_metadata_import`**
- Read the source of `cocosearch.indexer.flow` using `inspect.getsource`
- Assert the string `"from cocosearch.indexer.metadata import extract_devops_metadata"` is in the source
- This validates the import wiring at the source level

**Test 4: `test_flow_source_has_metadata_transform`**
- Read the source of `cocosearch.indexer.flow` using `inspect.getsource`
- Assert `'chunk["metadata"]'` appears in the source (the transform assignment)
- Assert `'extract_devops_metadata'` appears in the source (the function reference)
- Assert `'language=file["extension"]'` appears in the source (correct kwarg)

**Test 5: `test_flow_source_collects_metadata_fields`**
- Read the source of `cocosearch.indexer.flow` using `inspect.getsource`
- Assert all three metadata field patterns appear in the collect call:
  - `'block_type=chunk["metadata"]["block_type"]'`
  - `'hierarchy=chunk["metadata"]["hierarchy"]'`
  - `'language_id=chunk["metadata"]["language_id"]'`

**Test 6: `test_flow_source_preserves_primary_keys`**
- Read the source of `cocosearch.indexer.flow` using `inspect.getsource`
- Assert `'primary_key_fields=["filename", "location"]'` appears in the source
- This validates REQ-17 (stable primary keys)

**Test 7: `test_create_code_index_flow_with_metadata_succeeds`**
- Call `create_code_index_flow` with standard args (same pattern as `test_creates_flow_with_name`)
- Assert the returned flow is not None
- This validates the flow definition still builds without errors after metadata wiring

Add `import inspect` at the top of the file alongside the existing imports.

Do NOT modify any existing tests. Only ADD the new `TestMetadataIntegration` class at the end of the file.
  </action>
  <verify>
1. `python -m pytest tests/indexer/test_flow.py -v` -- all tests pass (existing + new)
2. `python -m pytest tests/indexer/test_flow.py -k "TestMetadataIntegration" -v` -- all 7 new tests pass
3. `python -m pytest tests/indexer/test_flow.py --tb=short` -- no failures
  </verify>
  <done>
- 7 new tests in `TestMetadataIntegration` class all pass
- Tests verify: import wiring, transform call presence, collect kwargs, primary key stability
- All existing tests still pass (no regressions)
- Tests do not require database or Ollama connections (source inspection + import checks only)
  </done>
</task>

</tasks>

<verification>
After both tasks complete:

1. **All tests pass:**
   ```
   python -m pytest tests/indexer/test_flow.py -v
   ```
   Expected: All existing tests pass + 7 new tests pass.

2. **flow.py has correct wiring (spot checks):**
   ```
   grep "extract_devops_metadata" src/cocosearch/indexer/flow.py
   ```
   Expected: 2 matches (import line + transform call).

   ```
   grep "block_type\|hierarchy\|language_id" src/cocosearch/indexer/flow.py
   ```
   Expected: 3 matches (one per metadata field in collect call).

   ```
   grep "primary_key_fields" src/cocosearch/indexer/flow.py
   ```
   Expected: `["filename", "location"]` unchanged.

3. **No unrelated changes:**
   ```
   git diff --stat
   ```
   Expected: Only `src/cocosearch/indexer/flow.py` and `tests/indexer/test_flow.py` modified.

4. **Metadata module still works standalone:**
   ```
   python -m pytest tests/indexer/test_metadata.py -v
   ```
   Expected: All 53 metadata tests still pass.
</verification>

<success_criteria>
- REQ-14: ALREADY COMPLETE (custom_languages wired in Phase 1, line 67 of flow.py)
- REQ-15: extract_devops_metadata transform call added after chunking, before collect
- REQ-16: Three new fields (block_type, hierarchy, language_id) added to collect() -- PostgreSQL columns are auto-created by CocoIndex schema inference on next `flow.setup()` call
- REQ-17: Primary keys remain ["filename", "location"] -- export call unchanged
- All tests pass (existing + 7 new metadata integration tests)
- Only flow.py and test_flow.py modified
</success_criteria>

<output>
After completion, create `.planning/phases/10-flow-integration-and-schema/10-01-SUMMARY.md`
</output>
